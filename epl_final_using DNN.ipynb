{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9709e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pprint\n",
    "import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple,OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from unicodedata import category\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix\n",
    "\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3286998",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"results.csv\"\n",
    "df = pd.read_csv(path, encoding='windows-1254')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f188aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14T00:00:00Z</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14T00:00:00Z</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>QPR</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14T00:00:00Z</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14T00:00:00Z</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14T00:00:00Z</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11108</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>2022-04-09T17:30:00Z</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>2022-04-10T14:00:00Z</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11110</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>2022-04-10T14:00:00Z</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11111</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>2022-04-10T14:00:00Z</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11112</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>2022-04-10T16:30:00Z</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11113 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season              DateTime     HomeTeam        AwayTeam  FTHG  FTAG  \\\n",
       "0      1993-94  1993-08-14T00:00:00Z      Arsenal        Coventry     0     3   \n",
       "1      1993-94  1993-08-14T00:00:00Z  Aston Villa             QPR     4     1   \n",
       "2      1993-94  1993-08-14T00:00:00Z      Chelsea       Blackburn     1     2   \n",
       "3      1993-94  1993-08-14T00:00:00Z    Liverpool  Sheffield Weds     2     0   \n",
       "4      1993-94  1993-08-14T00:00:00Z     Man City           Leeds     1     1   \n",
       "...        ...                   ...          ...             ...   ...   ...   \n",
       "11108  2021-22  2022-04-09T17:30:00Z  Aston Villa       Tottenham     0     4   \n",
       "11109  2021-22  2022-04-10T14:00:00Z    Brentford        West Ham     2     0   \n",
       "11110  2021-22  2022-04-10T14:00:00Z    Leicester  Crystal Palace     2     1   \n",
       "11111  2021-22  2022-04-10T14:00:00Z      Norwich         Burnley     2     0   \n",
       "11112  2021-22  2022-04-10T16:30:00Z     Man City       Liverpool     2     2   \n",
       "\n",
       "      FTR  HTHG  HTAG  HTR  ...  HST  AST   HC   AC    HF    AF   HY   AY  \\\n",
       "0       A   NaN   NaN  NaN  ...  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN   \n",
       "1       H   NaN   NaN  NaN  ...  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN   \n",
       "2       A   NaN   NaN  NaN  ...  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN   \n",
       "3       H   NaN   NaN  NaN  ...  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN   \n",
       "4       D   NaN   NaN  NaN  ...  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN   \n",
       "...    ..   ...   ...  ...  ...  ...  ...  ...  ...   ...   ...  ...  ...   \n",
       "11108   A   0.0   1.0    A  ...  8.0  5.0  9.0  3.0  12.0  14.0  2.0  3.0   \n",
       "11109   H   0.0   0.0    D  ...  7.0  1.0  4.0  6.0   2.0   6.0  0.0  1.0   \n",
       "11110   H   2.0   0.0    H  ...  3.0  3.0  3.0  4.0  11.0  12.0  1.0  1.0   \n",
       "11111   H   1.0   0.0    H  ...  6.0  4.0  6.0  7.0  12.0  10.0  1.0  1.0   \n",
       "11112   D   2.0   1.0    H  ...  5.0  4.0  4.0  1.0   9.0  11.0  1.0  4.0   \n",
       "\n",
       "        HR   AR  \n",
       "0      NaN  NaN  \n",
       "1      NaN  NaN  \n",
       "2      NaN  NaN  \n",
       "3      NaN  NaN  \n",
       "4      NaN  NaN  \n",
       "...    ...  ...  \n",
       "11108  0.0  0.0  \n",
       "11109  0.0  0.0  \n",
       "11110  0.0  0.0  \n",
       "11111  0.0  0.0  \n",
       "11112  0.0  0.0  \n",
       "\n",
       "[11113 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdee3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest(data, iforest):\n",
    "    # iforest in an instance of isolation_forest\n",
    "    # Returns 1 of inliers, -1 for outliers\n",
    "    pred = iforest.fit_predict(data)\n",
    "    outlier_index = np.where(pred == -1)\n",
    "    outlier_values = data.iloc[outlier_index]\n",
    "    return outlier_index, outlier_values\n",
    "\n",
    "iforest = IsolationForest(n_estimators=100, max_samples='auto',\n",
    "                          contamination=0.1, max_features=1.0,\n",
    "                          bootstrap=False, n_jobs=-1, random_state=1)\n",
    "\n",
    "def preprocess(data):\n",
    "    data.columns = [col.lower() for col in data.columns]\n",
    "    data.datetime = pd.to_datetime(data.datetime).dt.date\n",
    "    data.drop(data.loc[data['season'].str.contains(\n",
    "        '1993|1994|1995|1996|1997|1998|1999', regex=True)].index, inplace=True)\n",
    "    data.sort_values(['datetime', 'hometeam', 'awayteam',\n",
    "                     'referee'], ascending=True, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    points_h_map = {'H': 3, 'D': 1, 'A': 0}\n",
    "    points_a_map = {'H': 0, 'D': 1, 'A': 3}\n",
    "    data['hp'] = data['ftr'].map(points_h_map)\n",
    "    data['ap'] = data['ftr'].map(points_a_map)\n",
    "    data['hhp'] = data['htr'].map(points_h_map)\n",
    "    data['hap'] = data['htr'].map(points_a_map)\n",
    "#     index,values=isolation_forest(data.select_dtypes('number'),iforest)\n",
    "#     data.drop(index[0],axis=0,inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "pack = {}\n",
    "home = ['hometeam', 'FTHG', 'hthg', 'hs',\n",
    "        'hst', 'hc', 'hf', 'hy', 'hr', 'hp', 'hhp']\n",
    "away = ['awayteam', 'ftag', 'htag', 'as',\n",
    "        'ast', 'ac', 'af', 'ay', 'ar', 'ap', 'hap']\n",
    "objects = ['season', 'datetime', 'ftr', 'htr', 'referee']\n",
    "feature_names = ['ftg', 'htg', 's', 'st', 'c', 'f', 'y', 'r', 'p', 'hp']\n",
    "\n",
    "data = preprocess(df)\n",
    "data = data.reindex(columns=objects+home+away)\n",
    "\n",
    "home_data = data[objects+home]\n",
    "away_data = data[objects+away]\n",
    "\n",
    "pack['data'] = data\n",
    "pack['home_data'] = home_data\n",
    "pack['away_data'] = away_data\n",
    "pack['home'] = home\n",
    "pack['away'] = away\n",
    "pack['objects'] = objects\n",
    "pack['feature_names'] = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909ceaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self, home, away, objects, feature_names, home_data, away_data, data):\n",
    "        self.home = home\n",
    "        self.away = away\n",
    "        self.objects = objects\n",
    "        self.feature_names = feature_names\n",
    "        self.home_data1 = home_data.copy()\n",
    "        self.away_data1 = away_data.copy()\n",
    "        self.home_data = home_data.copy()\n",
    "        self.away_data = away_data.copy()\n",
    "        self.data = data\n",
    "\n",
    "    def rol_hac(self):\n",
    "        # rolling home and away combined\n",
    "        \"\"\"making a rolling of all attributes representing a team offense\"\"\"\n",
    "\n",
    "        self.away_data1.columns = self.objects + self.home  # changed away to look like home\n",
    "        combined_data = pd.concat([self.home_data1, self.away_data1],\n",
    "                                  ignore_index=True)  # cancatted it\n",
    "        combined_data['identification'] = np.array([np.ones(self.home_data1.shape[0]), np.zeros(\n",
    "            self.home_data1.shape[0])], dtype=np.int64).reshape(-1, 1)  # making an identifier to split later\n",
    "        # combined data-very important its data raveled vertically\n",
    "\n",
    "        rol_hac = pd.DataFrame(index=combined_data.index)\n",
    "        features_to_rol = self.home[1:]\n",
    "        for col in features_to_rol:\n",
    "            feature = combined_data.groupby('hometeam', as_index=False)[col].rolling(\n",
    "                window=10, center=True, min_periods=5).mean().shift(1).fillna(method='bfill')[col]\n",
    "            rol_hac[col] = feature\n",
    "        home_df = rol_hac[combined_data.identification == 1]\n",
    "        away_df = rol_hac[combined_data.identification ==\n",
    "                          0].reset_index(drop=True)\n",
    "        # hr-home rolling but its offensive\n",
    "        home_df.columns = [i+'_hr'for i in self.feature_names]\n",
    "        # away rolling but offensive\n",
    "        away_df.columns = [i+'_ar'for i in self.feature_names]\n",
    "        # suffixes are for overlapping columns\n",
    "        rol_features = home_df.join(away_df)\n",
    "        return rol_features\n",
    "\n",
    "    def rol_hac_d(self):\n",
    "        \"\"\"this features are rolling home and away combined attributes(attributes like home shots,home fouls away yellow acrds etc )\n",
    "        conceded by home and away teams until the previous match\n",
    "        hs_c=shots conceded by the  home team until the previous match\n",
    "        ha_c=shots conceded by the away team until the previous match ,i think you get the idea\n",
    "        \"\"\"\n",
    "\n",
    "        self.home_data.columns = self.objects+self.away  # changed away to look like home\n",
    "        combined_data = pd.concat([self.away_data, self.home_data],\n",
    "                                  ignore_index=True)  # cancatted it\n",
    "        combined_data['identification'] = np.array([np.ones(self.home_data.shape[0]), np.zeros(\n",
    "            self.home_data.shape[0])], dtype=np.int64).reshape(-1, 1)  # making an identifier to split later\n",
    "        # ones represent what is home teams defence and zeros represent away teams defence\n",
    "\n",
    "        rol_hac = pd.DataFrame(index=combined_data.index)\n",
    "        features_to_rol = self.away[1:]\n",
    "        for col in features_to_rol:\n",
    "            feature = combined_data.groupby('awayteam', as_index=False)[col].rolling(\n",
    "                window=10, center=True, min_periods=5).mean().shift(1).fillna(method='bfill')[col]\n",
    "            rol_hac[col] = feature  # c indicates conceded\n",
    "        home_df = rol_hac[combined_data.identification == 1]\n",
    "        # -chr-conceded home rolling\n",
    "        home_df.columns = [i+'_chr'for i in self.feature_names]\n",
    "        away_df = rol_hac[combined_data.identification ==\n",
    "                          0].reset_index(drop=True)\n",
    "        # -car-conceded away rolling\n",
    "        away_df.columns = [i+'_car'for i in self.feature_names]\n",
    "        rol_features = home_df.join(away_df)\n",
    "        return rol_features\n",
    "\n",
    "    def other_features(self, data):\n",
    "        data['day'] = data['datetime'].apply(lambda x: x.isoweekday())\n",
    "        data.ftr = data.ftr.map({'H': 2, 'A': 1, 'D': 0})\n",
    "        data.htr = data.htr.map({'H': 2, 'A': 1, 'D': 0})\n",
    "        return data\n",
    "\n",
    "    def execute(self):\n",
    "        rollin_features_a = self.rol_hac()\n",
    "        rollin_features_d = self.rol_hac_d()\n",
    "        object_data = self.data[self.objects+['hometeam', 'awayteam']]\n",
    "        data = object_data.join([rollin_features_a, rollin_features_d])\n",
    "        data_all_features = self.other_features(data)\n",
    "        return data_all_features\n",
    "\n",
    "\n",
    "def encoder(data, features):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    oe = OrdinalEncoder()\n",
    "    data[features] = oe.fit_transform(data[features])\n",
    "    return data\n",
    "\n",
    "\n",
    "def features_targets(data, selected_features=None):\n",
    "    # data = data.select_dtypes('number')  #selecting only numerical features for starters\n",
    "    container = namedtuple('container', ['trainx', 'trainy'])\n",
    "    if selected_features is not None:\n",
    "        features = data[selected_features]\n",
    "    else:\n",
    "        features=data\n",
    "    # these not rolling original results for reference dont need anymore!\n",
    "    ind_feats = features.drop(['ftr', 'htr','datetime','referee'], axis=1)\n",
    "    ind_feats = encoder(ind_feats, ['hometeam', 'awayteam', 'season'])\n",
    "    datas = container(ind_feats, features['ftr'])\n",
    "    return datas\n",
    "\n",
    "\n",
    "def mutual_information(x, y, mask=None):\n",
    "    \"\"\"function calculates the mi score in descendinhg trend given x and y\"\"\"\n",
    "    if mask is not None:\n",
    "        mi = mutual_info_classif(x.iloc[:, :mask], y)\n",
    "        mi = pd.DataFrame(mi, columns=['mi_score'], index=x.columns[:mask])\n",
    "    elif mask is None:\n",
    "        mi = mutual_info_classif(x, y)\n",
    "        mi = pd.DataFrame(mi, columns=['mi_score'], index=x.columns)\n",
    "\n",
    "    mi = mi.sort_values(\"mi_score\", ascending=False)\n",
    "    return mi\n",
    "\n",
    "\n",
    "def pca_ing(x, standardize=True):\n",
    "    \"\"\"function standardizes the data is not standardized and performs pca and outputs its componets in a df also loadings\"\"\"\n",
    "    if standardize:\n",
    "        sc = StandardScaler()\n",
    "        x_scaled = sc.fit_transform(x)\n",
    "        x = pd.DataFrame(x_scaled, columns=x.columns)\n",
    "    pca = PCA()\n",
    "    x_pca = pca.fit_transform(x)\n",
    "    components = [f'pca_{i}' for i in x.columns.values]\n",
    "    x_pca = pd.DataFrame(x_pca, columns=components)\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T, columns=components, index=x.columns)\n",
    "    return x_pca, loadings\n",
    "\n",
    "\n",
    "def auto_best_features(x, y,  n_features, standardize_on_pca=True):\n",
    "    \"\"\"best n_features(having most mi scores) among x and its pca version n_features=-1 for all features \"\"\"\n",
    "    x_pca, _ = pca_ing(x, standardize=standardize_on_pca)\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    all_features = x.join(x_pca)\n",
    "    mutual_info = mutual_information(all_features, y)\n",
    "    selected_cols = mutual_info.index.values[:n_features]\n",
    "    return all_features[selected_cols]\n",
    "\n",
    "\n",
    "def plotmi(mi):\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(5, 20), dpi=100)\n",
    "    sns.barplot(mi['mi_score'], mi.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b02f958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=0, \n",
    "                      objective='multi:softprob',\n",
    "                      tree_method='gpu_hist',\n",
    "                      verbosity=1,\n",
    "                      num_class=3\n",
    "                     )\n",
    "\n",
    "# scoring = make_scorer(partial(accuracy_score), greater_is_better=True)\n",
    "overdone_control = DeltaYStopper(delta=0.0001)\n",
    "time_limit_control = DeadlineStopper(total_time=60*60*1)\n",
    "\n",
    "search_spaces = {              \n",
    "            \n",
    "                'n_estimators': Integer(1, 500), #nmber of boosting steps\n",
    "                'max_depth': Integer(1, 100),  #max depth of base estimator\n",
    "                'learning_rate': Real(0.001, 1.0, 'uniform'), #weight in combining each steap of the boost must be small if n_estimators are very large\n",
    "                'reg_lambda': Real(1e-9, 5., 'uniform'), #l2 ref param\n",
    "                'max_leaves' : Integer(1,100), \n",
    "                'booster' : Categorical(['gbtree','gblinear','dart']),\n",
    "                'subsample': Real(0.1, 1.0, 'uniform'), #regularization by only using a randaom set given fraction of rows for traning each boost step\n",
    "                'sampling_method':Categorical(['uniform','gradient_based']),\n",
    "                'colsample_bytree': Real(0.1, 1.0, 'uniform'), #regularization by only using a random set of given fraction of column in each boost step \n",
    "                'predictor': Categorical(['gpu_predictor']),\n",
    "                'grow_policy': Categorical(['depthwise','lossguide'])\n",
    "    \n",
    "#                 'max_bin':\n",
    "#                 'gamma':\n",
    "#                 'gpu_id':\n",
    "#                 'monotone_constraints':\n",
    "#                 'interaction_constraints':\n",
    "#                 'single_precision_histogram':\n",
    "                \n",
    "                 }\n",
    "\n",
    "# num_iterations=1000,\n",
    "# feature_fraction=0.7,\n",
    "# scale_pos_weight=1.5,\n",
    "\n",
    "\n",
    "def optimizer(trainx, trainy, title, callbacks=None):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=0) #controllable split size-take care\n",
    "    cv_strategy = skf.split(trainx, trainy)\n",
    "    optimizer_fn = BayesSearchCV(estimator=model,\n",
    "                              search_spaces=search_spaces,\n",
    "                              scoring='f1_weighted',\n",
    "                              cv=cv_strategy,\n",
    "                              n_iter=120,\n",
    "                              n_points=1,\n",
    "                              n_jobs=1,\n",
    "                              iid=False,\n",
    "                              return_train_score=False,\n",
    "                              refit=False,\n",
    "                              optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                              random_state=0)\n",
    "\n",
    "    \n",
    "    start = time()\n",
    "    if callbacks is not None:\n",
    "        tqdm(optimizer_fn.fit(trainx, trainy, callback=[overdone_control, time_limit_control]))\n",
    "    else:\n",
    "        optimizer_fn.fit(trainx, trainy)\n",
    "\n",
    "    d = pd.DataFrame(optimizer_fn.cv_results_)\n",
    "    best_score = optimizer_fn.best_score_\n",
    "    best_score_std = d.iloc[optimizer_fn.best_index_].std_test_score\n",
    "    best_params = optimizer_fn.best_params_\n",
    "\n",
    "    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \" + u\"\\u00B1\" +\n",
    "          \" %.3f\") % (time() - start, len(optimizer_fn.cv_results_['params']), best_score, best_score_std))\n",
    "    print('Best parameters:')\n",
    "    pprint.pprint(best_params)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f0f686",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FTHG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FTHG'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21260\\1809680176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrainx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21260\\2334519359.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mrollin_features_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrol_hac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mrollin_features_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrol_hac_d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mobject_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hometeam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'awayteam'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21260\\2334519359.py\u001b[0m in \u001b[0;36mrol_hac\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mfeatures_to_rol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures_to_rol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             feature = combined_data.groupby('hometeam', as_index=False)[col].rolling(\n\u001b[0m\u001b[0;32m     28\u001b[0m                 window=10, center=True, min_periods=5).mean().shift(1).fillna(method='bfill')[col]\n\u001b[0;32m     29\u001b[0m             \u001b[0mrol_hac\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method)\u001b[0m\n\u001b[0;32m   2874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2875\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2876\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2877\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[1;34m(self, key, level, indexer)\u001b[0m\n\u001b[0;32m   3156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3158\u001b[1;33m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc_single_level_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexsort_depth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_get_loc_single_level_index\u001b[1;34m(self, level_index, key)\u001b[0m\n\u001b[0;32m   2807\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FTHG'"
     ]
    }
   ],
   "source": [
    "feat = Features(**pack)\n",
    "data = feat.execute()\n",
    "container = features_targets(data)\n",
    "trainx = container.trainx\n",
    "trainy = container.trainy\n",
    "\n",
    "trainx,valx,trainy,valy=train_test_split(trainx,trainy,test_size=0.2,stratify=trainy)\n",
    "trainx.reset_index(inplace=True,drop=True)\n",
    "valx.reset_index(inplace=True,drop=True)\n",
    "trainy.reset_index(inplace=True,drop=True)\n",
    "valy.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a41976",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21260\\3253521378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'XGBoost_classif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mt_preds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mv_preds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainx' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = optimizer(trainx,trainy, 'XGBoost_classif')\n",
    "model.set_params(**best_params)\n",
    "model.fit(trainx,trainy)\n",
    "t_preds=model.predict(trainx)\n",
    "v_preds=model.predict(valx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0aec9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a922d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdc94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
